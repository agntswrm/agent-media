import { createRunpod } from '@runpod/ai-sdk-provider';
import { generateImage, experimental_transcribe as transcribe } from 'ai';
import { writeFile, readFile, stat } from 'node:fs/promises';
import type {
  MediaProvider,
  MediaResult,
  ActionOptions,
  ActionContext,
  GenerateOptions,
  EditOptions,
  VideoGenerateOptions,
  TranscribeOptions,
  TranscriptionData,
} from '@agent-media/core';
import {
  createSuccess,
  createError,
  createTranscriptionSuccess,
  ensureOutputDir,
  resolveOutputFilename,
  getOutputPath,
  ErrorCodes,
} from '@agent-media/core';
import { generateVideoRunpod } from '../video-gen/runpod.js';

/**
 * Actions supported by the runpod provider
 */
const SUPPORTED_ACTIONS = ['generate', 'edit', 'video-generate', 'transcribe'];

/**
 * Runpod provider for image generation, editing, and transcription
 * Requires RUNPOD_API_KEY environment variable
 *
 * Supported actions:
 * - generate: Text-to-image using alibaba/wan-2.6
 * - edit: Image-to-image editing using google/nano-banana-pro-edit
 * - transcribe: Audio-to-text using pruna/whisper-v3-large (no diarization support)
 */
export const runpodProvider: MediaProvider = {
  name: 'runpod',

  supports(action: string): boolean {
    return SUPPORTED_ACTIONS.includes(action);
  },

  async execute(
    actionConfig: ActionOptions,
    context: ActionContext
  ): Promise<MediaResult> {
    const apiKey = process.env['RUNPOD_API_KEY'];

    if (!apiKey) {
      return createError(
        ErrorCodes.API_ERROR,
        'RUNPOD_API_KEY environment variable is not set'
      );
    }

    try {
      await ensureOutputDir(context.outputDir);

      switch (actionConfig.action) {
        case 'generate':
          return await executeGenerate(actionConfig.options, context, apiKey);
        case 'edit':
          return await executeEdit(actionConfig.options, context, apiKey);
        case 'video-generate':
          return await executeVideoGenerate(actionConfig.options, context, apiKey);
        case 'transcribe':
          return await executeTranscribe(actionConfig.options, context, apiKey);
        default:
          return createError(
            ErrorCodes.INVALID_INPUT,
            `Action '${actionConfig.action}' not supported by runpod provider`
          );
      }
    } catch (error) {
      const message = error instanceof Error ? error.message : String(error);
      return createError(ErrorCodes.PROVIDER_ERROR, message);
    }
  },
};

/**
 * Execute generate action using Runpod alibaba/wan-2.6 model via AI SDK
 */
async function executeGenerate(
  options: GenerateOptions,
  context: ActionContext,
  apiKey: string
): Promise<MediaResult> {
  const { prompt, width = 1280, height = 720, seed } = options;

  if (!prompt) {
    return createError(ErrorCodes.INVALID_INPUT, 'Prompt is required for image generation');
  }

  const runpod = createRunpod({ apiKey });

  const { image } = await generateImage({
    model: runpod.image('alibaba/wan-2.6'),
    prompt,
    size: `${width}x${height}`,
    seed,
  });

  const outputFilename = resolveOutputFilename('png', 'generated', context.outputName);
  const outputPath = getOutputPath(context.outputDir, outputFilename);

  await writeFile(outputPath, image.uint8Array);

  const stats = await stat(outputPath);

  return createSuccess({
    mediaType: 'image',
    action: 'generate',
    provider: 'runpod',
    outputPath: outputPath,
    mime: 'image/png',
    bytes: stats.size,
  });
}

/**
 * Convert a MediaInput to a Buffer
 */
async function toBuffer(input: { source: string; isUrl: boolean }): Promise<Buffer> {
  if (input.isUrl) {
    const response = await fetch(input.source);
    if (!response.ok) {
      throw new Error(`Failed to fetch input image: ${response.statusText}`);
    }
    const arrayBuffer = await response.arrayBuffer();
    return Buffer.from(arrayBuffer);
  } else {
    return readFile(input.source);
  }
}

/**
 * Execute edit action using Runpod google/nano-banana-pro-edit model via AI SDK
 * Supports multiple input images via prompt.images array
 */
async function executeEdit(
  options: EditOptions,
  context: ActionContext,
  apiKey: string
): Promise<MediaResult> {
  const { inputs, prompt } = options;

  if (!inputs || inputs.length === 0) {
    return createError(ErrorCodes.INVALID_INPUT, 'At least one input image is required for image editing');
  }

  if (!prompt) {
    return createError(ErrorCodes.INVALID_INPUT, 'Prompt is required for image editing');
  }

  const runpod = createRunpod({ apiKey });

  // Convert all inputs to buffers
  const imageBuffers = await Promise.all(inputs.map(toBuffer));

  const { image } = await generateImage({
    model: runpod.image('google/nano-banana-pro-edit'),
    prompt: {
      text: prompt,
      images: imageBuffers,
    },
  });

  const outputFilename = resolveOutputFilename('png', 'edited', context.outputName, context.inputSource);
  const outputPath = getOutputPath(context.outputDir, outputFilename);

  await writeFile(outputPath, image.uint8Array);

  const stats = await stat(outputPath);

  return createSuccess({
    mediaType: 'image',
    action: 'edit',
    provider: 'runpod',
    outputPath: outputPath,
    mime: 'image/png',
    bytes: stats.size,
  });
}

/**
 * Execute video-generate action using Runpod Wan 2.6 models
 */
async function executeVideoGenerate(
  options: VideoGenerateOptions,
  context: ActionContext,
  apiKey: string
): Promise<MediaResult> {
  const { prompt, input, duration, resolution, generateAudio } = options;

  if (!prompt) {
    return createError(ErrorCodes.INVALID_INPUT, 'Prompt is required for video generation');
  }

  try {
    const result = await generateVideoRunpod(
      {
        prompt,
        inputImage: input?.source,
        inputIsUrl: input?.isUrl,
        duration,
        resolution,
        generateAudio,
      },
      apiKey
    );

    const videoResponse = await fetch(result.url);
    if (!videoResponse.ok) {
      return createError(
        ErrorCodes.NETWORK_ERROR,
        `Failed to download generated video: ${videoResponse.statusText}`
      );
    }

    const arrayBuffer = await videoResponse.arrayBuffer();
    const buffer = Buffer.from(arrayBuffer);

    const outputFilename = resolveOutputFilename('mp4', 'generated', context.outputName, context.inputSource);
    const outputPath = getOutputPath(context.outputDir, outputFilename);

    await writeFile(outputPath, buffer);

    const stats = await stat(outputPath);

    return createSuccess({
      mediaType: 'video',
      action: 'video-generate',
      provider: 'runpod',
      outputPath: outputPath,
      mime: 'video/mp4',
      bytes: stats.size,
    });
  } catch (error) {
    const message = error instanceof Error ? error.message : String(error);
    return createError(ErrorCodes.PROVIDER_ERROR, message);
  }
}

/**
 * Execute transcribe action using Runpod pruna/whisper-v3-large model via AI SDK
 * Note: RunPod's Whisper model does NOT support diarization (speaker identification)
 */
async function executeTranscribe(
  options: TranscribeOptions,
  context: ActionContext,
  apiKey: string
): Promise<MediaResult> {
  const { input, diarize = false, language } = options;

  if (!input?.source) {
    return createError(ErrorCodes.INVALID_INPUT, 'Input source is required for transcription');
  }

  // Warn if diarization is requested - RunPod doesn't support it
  if (diarize) {
    console.warn('Warning: RunPod provider does not support diarization (speaker identification). Use fal or replicate for diarization.');
  }

  const runpod = createRunpod({ apiKey });

  // Prepare audio input - AI SDK accepts Buffer, Uint8Array, or URL
  let audioInput: Buffer | string;
  if (input.isUrl) {
    audioInput = input.source;
  } else {
    audioInput = await readFile(input.source);
  }

  // Build provider options for runpod
  const providerOptions: Record<string, unknown> = {};

  if (language) {
    providerOptions['language'] = language;
  }

  // Call transcription via AI SDK
  const result = await transcribe({
    model: runpod.transcription('pruna/whisper-v3-large'),
    audio: audioInput,
    providerOptions: Object.keys(providerOptions).length > 0
      ? { runpod: providerOptions as Record<string, string | number | boolean> }
      : undefined,
  });

  // Transform to our TranscriptionData format
  const transcription: TranscriptionData = {
    text: result.text || '',
    language: result.language || language || 'unknown',
    segments: (result.segments || []).map(segment => ({
      start: segment.startSecond,
      end: segment.endSecond,
      text: segment.text,
    })),
  };

  // Save transcription to JSON file
  const outputFilename = resolveOutputFilename('json', 'transcription', context.outputName, context.inputSource);
  const outputPath = getOutputPath(context.outputDir, outputFilename);

  await writeFile(outputPath, JSON.stringify(transcription, null, 2));

  return createTranscriptionSuccess({
    mediaType: 'audio',
    provider: 'runpod',
    outputPath: outputPath,
    transcription,
  });
}

export default runpodProvider;
